{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 06 - Network Analysis of Mitochondrial Genomes from FASTA Data\n",
    "\n",
    "This notebook focuses on constructing and analyzing a similarity network of mitochondrial genomes based *solely* on features extractable from FASTA sequence files. This approach allows us to understand relationships and patterns between genomes using fundamental sequence characteristics.\n",
    "\n",
    "## Analysis Steps:\n",
    "1.  **Data Loading & Feature Extraction:** Read mitochondrial genome sequences from a FASTA file and extract basic features (length, GC content, nucleotide counts, base skews, dinucleotide frequencies).\n",
    "2.  **Feature Scaling:** Standardize the extracted numerical features to ensure all contribute equally to similarity calculations.\n",
    "3.  **Similarity Matrix Calculation:** Compute pairwise similarity (e.g., cosine similarity) between all genomes based on their feature vectors.\n",
    "4.  **Network Construction:** Build a graph where genomes are nodes and edges represent a high degree of similarity between them.\n",
    "5.  **Interactive Network Visualization:** Create a dynamic network graph using Plotly, allowing for interactive exploration including hovering over nodes to see detailed information.\n",
    "6.  **Network Statistics & Interpretation:** Calculate and discuss key network properties (e.g., density, connectivity, central nodes) and provide biological interpretations of the observed genomic relationships.\n",
    "\n",
    "**Author:** yashmgupta  \n",
    "**Date:** 2025-06-19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Import required libraries\n",
    "from Bio import SeqIO\n",
    "from Bio.SeqUtils import gc_fraction\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter, defaultdict\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import networkx as nx\n",
    "import plotly.graph_objects as go\n",
    "import plotly.offline as pyo\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "try:\n",
    "    import community as co # For community detection\n",
    "except ModuleNotFoundError:\n",
    "    print(\"'community' module not found. Attempting to install 'python-louvain'...\")\n",
    "    try:\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"python-louvain\"])\n",
    "        import community as co\n",
    "        print(\"'python-louvain' installed successfully and 'community' module imported.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to install 'python-louvain'. Please install it manually: pip install python-louvain. Error: {e}\")\n",
    "        # Re-raise to prevent further execution if the module is critical\n",
    "        raise\n",
    "\n",
    "\n",
    "# Initialize Plotly for offline use\n",
    "pyo.init_notebook_mode(connected=True)\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"All necessary libraries imported.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming \"All_orthomt.fasta\" is available in the environment\n",
    "input_fasta_all = \"All_orthomt.fasta\"\n",
    "try:\n",
    "    records_all = list(SeqIO.parse(input_fasta_all, \"fasta\"))\n",
    "    print(f\"Total sequences loaded from '{input_fasta_all}': {len(records_all)}\")\n",
    "\n",
    "    # Cell 3: Separate UNVERIFIED and VERIFIED records\n",
    "    unverified_records = [rec for rec in records_all if \"UNVERIFIED\" in rec.description]\n",
    "    verified_records   = [rec for rec in records_all if \"UNVERIFIED\" not in rec.description]\n",
    "\n",
    "    print(f\"UNVERIFIED sequences: {len(unverified_records)}\")\n",
    "    print(f\"VERIFIED sequences: {len(verified_records)}\")\n",
    "\n",
    "    # Cell 4: Save VERIFIED records to new FASTA\n",
    "    fasta_file = \"verified_only.fasta\" # This will be the input for network analysis\n",
    "    SeqIO.write(verified_records, fasta_file, \"fasta\")\n",
    "    print(f\"Verified-only FASTA saved to: {fasta_file}\")\n",
    "\n",
    "    # Cell 5: Save UNVERIFIED record IDs and descriptions to CSV\n",
    "    unverified_list = [{\"id\": rec.id, \"description\": rec.description} for rec in unverified_records]\n",
    "    df_unverified = pd.DataFrame(unverified_list)\n",
    "    csv_output_unverified = \"unverified_sequences.csv\"\n",
    "    df_unverified.to_csv(csv_output_unverified, index=False)\n",
    "    print(f\"UNVERIFIED sequence list saved to: {csv_output_unverified}\")\n",
    "\n",
    "    # Cell 6: Save UNVERIFIED records to new FASTA (as requested previously)\n",
    "    output_unverified_fasta = \"unverified_only.fasta\"\n",
    "    SeqIO.write(unverified_records, output_unverified_fasta, \"fasta\")\n",
    "    print(f\"Unverified-only FASTA saved to: {output_unverified_fasta}\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: Input FASTA file '{input_fasta_all}' not found. Please ensure it's in the correct directory.\")\n",
    "    exit() # Exit if the primary input file is missing\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during initial FASTA processing: {e}\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_threshold = 0.85 # Minimum cosine similarity for an edge\n",
    "\n",
    "print(\"\\n--- Starting Network Analysis ---\")\n",
    "print(f\"Using FASTA file: {fasta_file}\")\n",
    "print(f\"Similarity threshold: {similarity_threshold}\")\n",
    "\n",
    "# Cell 8: Data Loading & Feature Extraction for Network Analysis\n",
    "print(\"\\n--- Extracting features from sequences ---\")\n",
    "\n",
    "def calculate_base_skew(sequence):\n",
    "    \"\"\"Calculates GC and AT skew for a given sequence.\"\"\"\n",
    "    g = sequence.count('G')\n",
    "    c = sequence.count('C')\n",
    "    a = sequence.count('A')\n",
    "    t = sequence.count('T')\n",
    "\n",
    "    gc_skew = (g - c) / (g + c) if (g + c) > 0 else 0\n",
    "    at_skew = (a - t) / (a + t) if (a + t) > 0 else 0\n",
    "    return gc_skew, at_skew\n",
    "\n",
    "def calculate_dinucleotide_frequencies(sequence):\n",
    "    \"\"\"Calculates the frequencies of all 16 dinucleotides.\"\"\"\n",
    "    dinucleotides = defaultdict(int)\n",
    "    total_dinucleotides = 0\n",
    "    for i in range(len(sequence) - 1):\n",
    "        dinucleotide = sequence[i:i+2].upper()\n",
    "        if all(base in 'ATGC' for base in dinucleotide):\n",
    "            dinucleotides[dinucleotide] += 1\n",
    "            total_dinucleotides += 1\n",
    "\n",
    "    frequencies = {\n",
    "        dino: count / total_dinucleotides if total_dinucleotides > 0 else 0\n",
    "        for dino, count in dinucleotides.items()\n",
    "    }\n",
    "    # Ensure all 16 dinucleotides are present, even if frequency is 0\n",
    "    all_dinucleotides = [a + b for a in 'ATGC' for b in 'ATGC']\n",
    "    for dino in all_dinucleotides:\n",
    "        if dino not in frequencies:\n",
    "            frequencies[dino] = 0\n",
    "    return frequencies\n",
    "\n",
    "extracted_features = []\n",
    "try:\n",
    "    for record in SeqIO.parse(fasta_file, \"fasta\"):\n",
    "        sequence_id = record.id\n",
    "        full_description = record.description\n",
    "        sequence = str(record.seq).upper()\n",
    "\n",
    "        # Attempt to parse organism name from description\n",
    "        organism = \"Unknown\"\n",
    "        parts = full_description.split(' ')\n",
    "        if len(parts) > 1:\n",
    "            # Common pattern: \"Accession_ID SpeciesName [mitochondrion] other_info\"\n",
    "            # Try to get the first two words as species name, then refine\n",
    "            organism_guess = \" \".join(parts[1:3]).replace(\"mitochondrion\", \"\").strip()\n",
    "            # Remove any trailing bracketed text, common for taxonomy\n",
    "            organism = organism_guess.split('[')[0].strip()\n",
    "            # Basic capitalization for consistency\n",
    "            if organism and len(organism.split(' ')) > 1:\n",
    "                organism = ' '.join([word.capitalize() if i == 0 else word for i, word in enumerate(organism.split(' '))])\n",
    "            elif organism:\n",
    "                 organism = organism.capitalize()\n",
    "            # Fallback if organism is still empty or too short\n",
    "            if not organism or len(organism) < 3:\n",
    "                organism = \"Unknown\"\n",
    "\n",
    "\n",
    "        seq_len = len(sequence)\n",
    "        gc_cont = gc_fraction(sequence) if seq_len > 0 else 0\n",
    "        \n",
    "        a_count = sequence.count('A')\n",
    "        t_count = sequence.count('T')\n",
    "        g_count = sequence.count('G')\n",
    "        c_count = sequence.count('C')\n",
    "\n",
    "        gc_skew, at_skew = calculate_base_skew(sequence)\n",
    "        dinucleotide_freqs = calculate_dinucleotide_frequencies(sequence)\n",
    "\n",
    "        row = {\n",
    "            \"sequence_id\": sequence_id,\n",
    "            \"organism\": organism,\n",
    "            \"full_info\": full_description, # Keep full info for hover text\n",
    "            \"length\": seq_len,\n",
    "            \"gc_content\": gc_cont,\n",
    "            \"A_count\": a_count,\n",
    "            \"T_count\": t_count,\n",
    "            \"G_count\": g_count,\n",
    "            \"C_count\": c_count,\n",
    "            \"GC_skew\": gc_skew,\n",
    "            \"AT_skew\": at_skew,\n",
    "            **dinucleotide_freqs # Unpack dinucleotide frequencies\n",
    "        }\n",
    "        extracted_features.append(row)\n",
    "\n",
    "    df_features = pd.DataFrame(extracted_features)\n",
    "\n",
    "    # Handle potential duplicate sequence_ids\n",
    "    if df_features['sequence_id'].duplicated().any():\n",
    "        warnings.warn(\"Duplicate sequence_ids found. Keeping the first occurrence.\")\n",
    "        df_features.drop_duplicates(subset='sequence_id', keep='first', inplace=True)\n",
    "\n",
    "    df_features.set_index(\"sequence_id\", inplace=True)\n",
    "\n",
    "    print(f\"Extracted features for {len(df_features)} sequences.\")\n",
    "    print(\"First 5 rows of extracted features:\")\n",
    "    print(df_features.head())\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: Processed FASTA file '{fasta_file}' not found. Please ensure it exists after initial processing.\")\n",
    "    exit()\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during feature extraction: {e}\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Scaling numerical features ---\")\n",
    "\n",
    "# Separate numerical features from descriptive columns\n",
    "X = df_features.drop(columns=['organism', 'full_info'])\n",
    "y = df_features['organism'] # Keep organism for coloring/analysis\n",
    "\n",
    "# Initialize StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit and transform the numerical features\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Create a new DataFrame with scaled features\n",
    "df_scaled_features = pd.DataFrame(X_scaled, columns=X.columns, index=X.index)\n",
    "\n",
    "print(f\"Data after feature engineering: {df_scaled_features.shape[0]} sequences, {df_scaled_features.shape[1]} features.\")\n",
    "print(\"First 5 rows of scaled features:\")\n",
    "print(df_scaled_features.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10: Similarity Matrix Calculation and Network Construction\n",
    "print(\"\\n--- Calculating similarity matrix and constructing network ---\")\n",
    "\n",
    "# Calculate cosine similarity between all pairs of scaled feature vectors\n",
    "similarity_matrix = cosine_similarity(X_scaled)\n",
    "\n",
    "# Convert to DataFrame for easier inspection, using sequence_ids as index/columns\n",
    "similarity_df = pd.DataFrame(similarity_matrix, index=df_scaled_features.index, columns=df_scaled_features.index)\n",
    "\n",
    "# Initialize a networkx graph\n",
    "network = nx.Graph()\n",
    "\n",
    "# Add nodes with attributes (organism, full_info)\n",
    "for seq_id in df_features.index:\n",
    "    network.add_node(seq_id, \n",
    "                     organism=df_features.loc[seq_id, 'organism'], \n",
    "                     full_info=df_features.loc[seq_id, 'full_info'])\n",
    "\n",
    "# Add edges based on similarity threshold\n",
    "edges_added_count = 0\n",
    "for i in range(len(similarity_df.index)):\n",
    "    for j in range(i + 1, len(similarity_df.columns)): # Avoid self-loops and duplicate edges\n",
    "        seq_id1 = similarity_df.index[i]\n",
    "        seq_id2 = similarity_df.columns[j]\n",
    "        similarity = similarity_df.iloc[i, j]\n",
    "\n",
    "        if similarity >= similarity_threshold:\n",
    "            network.add_edge(seq_id1, seq_id2, weight=similarity)\n",
    "            edges_added_count += 1\n",
    "\n",
    "print(f\"Network created with {network.number_of_nodes()} nodes and {network.number_of_edges()} edges.\")\n",
    "print(f\"Network density: {nx.density(network):.4f}\")\n",
    "print(f\"Number of connected components: {nx.number_connected_components(network)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 11: Interactive Network Visualization (Plotly)\n",
    "print(\"\\n--- Generating interactive network visualization ---\")\n",
    "\n",
    "if network.number_of_edges() == 0:\n",
    "    print(\"No edges in the network. Skipping network visualization.\")\n",
    "    # Ensure 'pos' is not defined if visualization is skipped to avoid errors later\n",
    "    pos = None \n",
    "else:\n",
    "    # Use a force-directed layout for node positioning\n",
    "    # Adjust k (optimal distance between nodes) and iterations for better layouts\n",
    "    pos = nx.spring_layout(network, k=0.3, iterations=50, dim=2) \n",
    "\n",
    "    # Prepare data for Plotly\n",
    "    edge_x = []\n",
    "    edge_y = []\n",
    "    edge_weights = []\n",
    "    for edge in network.edges():\n",
    "        x0, y0 = pos[edge[0]]\n",
    "        x1, y1 = pos[edge[1]]\n",
    "        edge_x.extend([x0, x1, None]) # 'None' creates a break in the line, preventing drawing between disconnected segments\n",
    "        edge_y.extend([y0, y1, None])\n",
    "        edge_weights.append(network.edges[edge]['weight'])\n",
    "\n",
    "    node_x = [pos[node][0] for node in network.nodes()]\n",
    "    node_y = [pos[node][1] for node in network.nodes()]\n",
    "\n",
    "    # Get node information for coloring and hover\n",
    "    unique_organisms = y.unique()\n",
    "    # Generate a discrete color palette using seaborn\n",
    "    palette = sns.color_palette(\"tab10\", n_colors=len(unique_organisms)).as_hex()\n",
    "    organism_color_map = {organism: palette[i] for i, organism in enumerate(unique_organisms)}\n",
    "    \n",
    "    node_colors = [organism_color_map.get(network.nodes[node]['organism'], '#CCCCCC') for node in network.nodes()] # Default color for unknown\n",
    "    node_hover_texts = [network.nodes[node]['full_info'] for node in network.nodes()]\n",
    "\n",
    "    # Create edge trace\n",
    "    edge_trace = go.Scatter(\n",
    "        x=edge_x,\n",
    "        y=edge_y,\n",
    "        line=dict(width=0.5, color='#888'),\n",
    "        hoverinfo='none',\n",
    "        mode='lines',\n",
    "        name='Edges' # Added name for clarity if debugging legend\n",
    "    )\n",
    "\n",
    "    # Create node trace\n",
    "    node_trace = go.Scatter(\n",
    "        x=node_x,\n",
    "        y=node_y,\n",
    "        mode='markers',\n",
    "        hoverinfo='text',\n",
    "        marker=dict(\n",
    "            showscale=False, # No continuous colorscale needed for discrete colors\n",
    "            color=node_colors, # Direct hex/RGB colors\n",
    "            size=10,\n",
    "            line_width=1),\n",
    "        text=node_hover_texts,\n",
    "        name='Nodes' # Added name for clarity if debugging legend\n",
    "    )\n",
    "\n",
    "    # Create a mapping for legend based on organism names\n",
    "    legend_points = []\n",
    "    for organism_name, color_hex in organism_color_map.items():\n",
    "        legend_points.append(go.Scatter(\n",
    "            x=[None], y=[None], # Dummy points\n",
    "            mode='markers',\n",
    "            marker=dict(size=10, color=color_hex, symbol='circle'), # Added symbol for consistent look\n",
    "            name=organism_name, # Use organism name as legend entry\n",
    "            hoverinfo='none',\n",
    "            showlegend=True # Ensure these dummy points show in legend\n",
    "        ))\n",
    "\n",
    "    fig = go.Figure(data=[edge_trace, node_trace] + legend_points,\n",
    "                    layout=go.Layout(\n",
    "                        title=dict(\n",
    "                            text='Mitochondrial Genome Similarity Network',\n",
    "                            font=dict(size=16) \n",
    "                        ),\n",
    "                        showlegend=True,\n",
    "                        hovermode='closest',\n",
    "                        margin=dict(b=20,l=5,r=5,t=40),\n",
    "                        annotations=[ dict(\n",
    "                            text=\"Network analysis based on FASTA-derived features\",\n",
    "                            showarrow=False,\n",
    "                            xref=\"paper\", yref=\"paper\",\n",
    "                            x=0.005, y=-0.002 ) ],\n",
    "                        xaxis=dict(showgrid=False, zeroline=False, showticklabels=False, mirror=True),\n",
    "                        yaxis=dict(showgrid=False, zeroline=False, showticklabels=False, mirror=True),\n",
    "                        height=800,\n",
    "                        template=\"plotly_white\" # Use a clean white background template\n",
    "                    ))\n",
    "\n",
    "    pyo.iplot(fig) # Display the interactive plot\n",
    "    html_output_path = \"06_interactive_network_plot.html\"\n",
    "    fig.write_html(html_output_path) # Save as HTML for external viewing\n",
    "    print(f\"Interactive network plot saved as {html_output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 12: Save Network Analysis Results to CSV (with centrality and clustering)\n",
    "print(\"\\n--- Saving network data to CSV files ---\")\n",
    "\n",
    "# 12.1 Calculate centrality measures and prepare node data\n",
    "node_data = []\n",
    "\n",
    "if network.number_of_nodes() > 0:\n",
    "    print(\"Calculating node centrality measures...\")\n",
    "    try:\n",
    "        degree_centrality = nx.degree_centrality(network)\n",
    "    except Exception as e:\n",
    "        print(f\"Could not calculate degree centrality: {e}\")\n",
    "        degree_centrality = {node: 0 for node in network.nodes()} # Default to 0\n",
    "    \n",
    "    try:\n",
    "        # Betweenness centrality can be computationally intensive for large graphs\n",
    "        betweenness_centrality = nx.betweenness_centrality(network)\n",
    "    except Exception as e:\n",
    "        print(f\"Could not calculate betweenness centrality: {e}\")\n",
    "        betweenness_centrality = {node: 0 for node in network.nodes()} # Default to 0\n",
    "\n",
    "    try:\n",
    "        closeness_centrality = nx.closeness_centrality(network)\n",
    "    except Exception as e:\n",
    "        print(f\"Could not calculate closeness centrality: {e}\")\n",
    "        closeness_centrality = {node: 0 for node in network.nodes()} # Default to 0\n",
    "\n",
    "else:\n",
    "    print(\"Network has no nodes, skipping centrality calculations.\")\n",
    "    degree_centrality = {}\n",
    "    betweenness_centrality = {}\n",
    "    closeness_centrality = {}\n",
    "\n",
    "\n",
    "for node_id, attributes in network.nodes(data=True):\n",
    "    node_info = {\n",
    "        \"node_id\": node_id,\n",
    "        \"organism\": attributes.get(\"organism\", \"N/A\"),\n",
    "        \"full_info\": attributes.get(\"full_info\", \"N/A\"),\n",
    "        \"x_pos\": pos[node_id][0] if pos and node_id in pos else None, # Check if pos exists\n",
    "        \"y_pos\": pos[node_id][1] if pos and node_id in pos else None, # Check if pos exists\n",
    "        \"degree_centrality\": degree_centrality.get(node_id, 0),\n",
    "        \"betweenness_centrality\": betweenness_centrality.get(node_id, 0),\n",
    "        \"closeness_centrality\": closeness_centrality.get(node_id, 0)\n",
    "    }\n",
    "    node_data.append(node_info)\n",
    "\n",
    "df_nodes = pd.DataFrame(node_data)\n",
    "output_nodes_csv = \"network_nodes.csv\"\n",
    "df_nodes.to_csv(output_nodes_csv, index=False)\n",
    "print(f\"Network node data saved to: {output_nodes_csv}\")\n",
    "\n",
    "# 12.2 Save Edge Data to CSV\n",
    "edge_data = []\n",
    "for u, v, attributes in network.edges(data=True):\n",
    "    edge_info = {\n",
    "        \"source\": u,\n",
    "        \"target\": v,\n",
    "        \"weight\": attributes.get(\"weight\", 0) # Default to 0 if weight not found\n",
    "    }\n",
    "    edge_data.append(edge_info)\n",
    "\n",
    "df_edges = pd.DataFrame(edge_data)\n",
    "output_edges_csv = \"network_edges.csv\"\n",
    "df_edges.to_csv(output_edges_csv, index=False)\n",
    "print(f\"Network edge data saved to: {output_edges_csv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 13: Community Detection and Representative Species\n",
    "print(\"\\n--- Performing Community Detection and Identifying Representative Species ---\")\n",
    "\n",
    "cluster_results = []\n",
    "# Ensure network has enough nodes and edges for meaningful community detection\n",
    "if network.number_of_nodes() > 1 and network.number_of_edges() > 0:\n",
    "    try:\n",
    "        # Compute the best partition using the Louvain method\n",
    "        partition = co.best_partition(network)\n",
    "        num_communities = len(set(partition.values()))\n",
    "        print(f\"Found {num_communities} communities.\")\n",
    "\n",
    "        # Add community/cluster ID to node data\n",
    "        # Ensure 'cluster_id' column is added correctly\n",
    "        df_nodes['cluster_id'] = df_nodes['node_id'].map(partition).fillna(-1).astype(int)\n",
    "\n",
    "        # Identify representative species for each cluster\n",
    "        cluster_representatives = {}\n",
    "        for cluster_id in sorted(set(partition.values())):\n",
    "            nodes_in_cluster = [node for node, cid in partition.items() if cid == cluster_id]\n",
    "            \n",
    "            # Get organisms for nodes in this cluster from the network's node attributes\n",
    "            organisms_in_cluster = []\n",
    "            for node_id in nodes_in_cluster:\n",
    "                organism = network.nodes[node_id].get('organism')\n",
    "                if organism and organism != \"N/A\" and organism != \"Unknown\": # Filter out default/unknown organisms\n",
    "                    organisms_in_cluster.append(organism)\n",
    "            \n",
    "            if organisms_in_cluster:\n",
    "                # Find the most common organism in the cluster\n",
    "                organism_counts = Counter(organisms_in_cluster)\n",
    "                most_common_organism = organism_counts.most_common(1)[0][0]\n",
    "                cluster_representatives[cluster_id] = most_common_organism\n",
    "            else:\n",
    "                cluster_representatives[cluster_id] = \"N/A (No identifiable organism)\"\n",
    "\n",
    "        # Prepare cluster summary data\n",
    "        for cluster_id, representative in cluster_representatives.items():\n",
    "            cluster_results.append({\n",
    "                \"cluster_id\": cluster_id,\n",
    "                \"representative_organism\": representative,\n",
    "                \"num_nodes_in_cluster\": list(partition.values()).count(cluster_id)\n",
    "            })\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error during community detection or representative species identification: {e}\")\n",
    "        print(\"Please ensure 'python-louvain' is installed (e.g., pip install python-louvain).\")\n",
    "        # Ensure 'cluster_id' column is added even if clustering fails for consistency\n",
    "        if 'cluster_id' not in df_nodes.columns:\n",
    "            df_nodes['cluster_id'] = -1 # Assign a default invalid cluster ID\n",
    "else:\n",
    "    print(\"Network is too small or has no edges for meaningful community detection.\")\n",
    "    if 'cluster_id' not in df_nodes.columns:\n",
    "        df_nodes['cluster_id'] = -1 # Assign a default invalid cluster ID\n",
    "\n",
    "# Save updated node data with cluster IDs\n",
    "output_nodes_clustered_csv = \"network_nodes_clustered.csv\"\n",
    "df_nodes.to_csv(output_nodes_clustered_csv, index=False)\n",
    "print(f\"Updated network node data with cluster IDs saved to: {output_nodes_clustered_csv}\")\n",
    "\n",
    "# Save cluster representatives to CSV\n",
    "if cluster_results:\n",
    "    df_clusters = pd.DataFrame(cluster_results)\n",
    "    output_clusters_csv = \"network_clusters_summary.csv\"\n",
    "    df_clusters.to_csv(output_clusters_csv, index=False)\n",
    "    print(f\"Cluster summary and representative species saved to: {output_clusters_csv}\")\n",
    "else:\n",
    "    print(\"No cluster summary to save as no clusters were identified.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 14: Visualize Network with Communities\n",
    "print(\"\\n--- Visualizing Network with Communities and Representative Species ---\")\n",
    "\n",
    "# --- NEW: Configuration for highlighting ---\n",
    "# Set the cluster ID you want to highlight. Set to None to show all clusters colored.\n",
    "# You can get cluster IDs from the 'network_clusters_summary.csv' file or the output of Cell 13.\n",
    "highlight_cluster_id = None # Example: Set to an integer like 0, 1, 2, etc., to highlight a specific cluster.\n",
    "\n",
    "\n",
    "if network.number_of_edges() == 0 or not network.nodes() or not 'cluster_id' in df_nodes.columns:\n",
    "    print(\"Cannot visualize communities: Network has no edges, no nodes, or clustering was not performed/failed.\")\n",
    "else:\n",
    "    # Ensure pos exists from previous visualization, if not, generate it\n",
    "    # This block is important as 'pos' is used for all node coordinates.\n",
    "    if 'pos' not in locals() or pos is None:\n",
    "        print(\"Node positions not found. Generating new spring layout for visualization.\")\n",
    "        pos = nx.spring_layout(network, k=0.3, iterations=50, dim=2)\n",
    "\n",
    "    # Re-create edge trace (similar to previous visualization)\n",
    "    edge_x = []\n",
    "    edge_y = []\n",
    "    for edge in network.edges():\n",
    "        x0, y0 = pos[edge[0]]\n",
    "        x1, y1 = pos[edge[1]]\n",
    "        edge_x.extend([x0, x1, None])\n",
    "        edge_y.extend([y0, y1, None])\n",
    "\n",
    "    edge_trace_cluster = go.Scatter(\n",
    "        x=edge_x,\n",
    "        y=edge_y,\n",
    "        line=dict(width=0.5, color='#888'),\n",
    "        hoverinfo='none',\n",
    "        mode='lines',\n",
    "        name='Edges',\n",
    "        showlegend=False # Edges don't need a legend entry for this view\n",
    "    )\n",
    "\n",
    "    # Get node information for coloring by cluster\n",
    "    unique_cluster_ids = df_nodes['cluster_id'].unique()\n",
    "    # Generate a discrete color palette\n",
    "    cluster_palette = sns.color_palette(\"hls\", n_colors=len(unique_cluster_ids)).as_hex()\n",
    "    # Create a mapping from cluster ID to color\n",
    "    cluster_color_map = {cluster_id: cluster_palette[i] for i, cluster_id in enumerate(sorted(unique_cluster_ids))}\n",
    "    \n",
    "    # --- NEW LOGIC: Conditional creation of node traces for highlighting ---\n",
    "    node_traces = []\n",
    "    \n",
    "    if highlight_cluster_id is not None:\n",
    "        # Mode 1: Highlight a specific cluster\n",
    "        nodes_for_highlighted_trace_x = []\n",
    "        nodes_for_highlighted_trace_y = []\n",
    "        colors_for_highlighted_trace = []\n",
    "        hover_texts_for_highlighted_trace = []\n",
    "\n",
    "        # Nodes not in the highlighted cluster will be gray\n",
    "        nodes_for_gray_trace_x = []\n",
    "        nodes_for_gray_trace_y = []\n",
    "        hover_texts_for_gray_trace = []\n",
    "        \n",
    "        # Determine representative organism for the highlighted cluster for legend\n",
    "        highlight_rep_org = \"N/A\"\n",
    "        for cr in cluster_results:\n",
    "            if cr['cluster_id'] == highlight_cluster_id:\n",
    "                highlight_rep_org = cr['representative_organism']\n",
    "                break\n",
    "\n",
    "        for node_id in network.nodes():\n",
    "            if node_id in df_nodes.index:\n",
    "                cluster_id_for_node = df_nodes.loc[node_id, 'cluster_id']\n",
    "                organism_for_node = network.nodes[node_id].get('organism', 'N/A')\n",
    "                full_info_for_node = network.nodes[node_id].get('full_info', 'N/A')\n",
    "\n",
    "                hover_text = f\"{full_info_for_node}<br>Cluster: {cluster_id_for_node}<br>Organism: {organism_for_node}\"\n",
    "                \n",
    "                if cluster_id_for_node == highlight_cluster_id:\n",
    "                    nodes_for_highlighted_trace_x.append(pos[node_id][0])\n",
    "                    nodes_for_highlighted_trace_y.append(pos[node_id][1])\n",
    "                    colors_for_highlighted_trace.append(cluster_color_map.get(cluster_id_for_node, '#CCCCCC'))\n",
    "                    hover_texts_for_highlighted_trace.append(hover_text)\n",
    "                else:\n",
    "                    nodes_for_gray_trace_x.append(pos[node_id][0])\n",
    "                    nodes_for_gray_trace_y.append(pos[node_id][1])\n",
    "                    hover_texts_for_gray_trace.append(hover_text)\n",
    "            else:\n",
    "                # Fallback for nodes in network but not in df_nodes (should ideally not happen)\n",
    "                nodes_for_gray_trace_x.append(pos[node_id][0])\n",
    "                nodes_for_gray_trace_y.append(pos[node_id][1])\n",
    "                hover_texts_for_gray_trace.append(f\"{node_id}<br>Cluster: N/A<br>Organism: N/A (Data Missing)\")\n",
    "\n",
    "        # Add trace for the highlighted cluster\n",
    "        if nodes_for_highlighted_trace_x:\n",
    "            node_traces.append(\n",
    "                go.Scatter(\n",
    "                    x=nodes_for_highlighted_trace_x,\n",
    "                    y=nodes_for_highlighted_trace_y,\n",
    "                    mode='markers',\n",
    "                    hoverinfo='text',\n",
    "                    marker=dict(\n",
    "                        showscale=False,\n",
    "                        color=colors_for_highlighted_trace,\n",
    "                        size=12,\n",
    "                        line=dict(color='Black', width=0.5),\n",
    "                        line_width=1\n",
    "                    ),\n",
    "                    text=hover_texts_for_highlighted_trace,\n",
    "                    name=f\"Highlighted: Cluster {highlight_cluster_id} ({highlight_rep_org})\",\n",
    "                    showlegend=True\n",
    "                )\n",
    "            )\n",
    "        \n",
    "        # Add trace for all other nodes (in gray)\n",
    "        if nodes_for_gray_trace_x:\n",
    "            node_traces.append(\n",
    "                go.Scatter(\n",
    "                    x=nodes_for_gray_trace_x,\n",
    "                    y=nodes_for_gray_trace_y,\n",
    "                    mode='markers',\n",
    "                    hoverinfo='text',\n",
    "                    marker=dict(\n",
    "                        showscale=False,\n",
    "                        color='#CCCCCC', # Gray for non-highlighted\n",
    "                        size=12,\n",
    "                        line=dict(color='Black', width=0.5),\n",
    "                        line_width=1\n",
    "                    ),\n",
    "                    text=hover_texts_for_gray_trace,\n",
    "                    name=\"Other Nodes (Gray)\",\n",
    "                    showlegend=True # Show this in legend so user knows what gray means\n",
    "                )\n",
    "            )\n",
    "\n",
    "    else: \n",
    "        # Mode 2: Show all clusters with separate traces for interactive toggling\n",
    "        for cluster_id in sorted(unique_cluster_ids):\n",
    "            # Filter nodes for the current cluster\n",
    "            cluster_nodes = [node_id for node_id in network.nodes() if node_id in df_nodes.index and df_nodes.loc[node_id, 'cluster_id'] == cluster_id]\n",
    "            \n",
    "            # Prepare data for this cluster's trace\n",
    "            cluster_node_x = [pos[node][0] for node in cluster_nodes]\n",
    "            cluster_node_y = [pos[node][1] for node in cluster_nodes]\n",
    "            cluster_node_hover_texts = [\n",
    "                f\"{network.nodes[node]['full_info']}<br>Cluster: {cluster_id}<br>Organism: {network.nodes[node]['organism']}\"\n",
    "                for node in cluster_nodes\n",
    "            ]\n",
    "\n",
    "            representative_org = \"N/A\"\n",
    "            for cr in cluster_results:\n",
    "                if cr['cluster_id'] == cluster_id:\n",
    "                    representative_org = cr['representative_organism']\n",
    "                    break\n",
    "\n",
    "            node_trace_cluster_i = go.Scatter(\n",
    "                x=cluster_node_x,\n",
    "                y=cluster_node_y,\n",
    "                mode='markers',\n",
    "                hoverinfo='text',\n",
    "                marker=dict(\n",
    "                    showscale=False,\n",
    "                    color=cluster_color_map.get(cluster_id, '#CCCCCC'), # Use specific cluster color\n",
    "                    size=12,\n",
    "                    line=dict(color='Black', width=0.5),\n",
    "                    line_width=1\n",
    "                ),\n",
    "                text=cluster_node_hover_texts,\n",
    "                name=f\"Cluster {cluster_id} ({representative_org})\", # Name for legend entry\n",
    "                showlegend=True # Ensure this trace appears in the legend\n",
    "            )\n",
    "            node_traces.append(node_trace_cluster_i)\n",
    "\n",
    "    # Combine edges and all node traces\n",
    "    fig_cluster = go.Figure(data=[edge_trace_cluster] + node_traces,\n",
    "                            layout=go.Layout(\n",
    "                                title=dict(\n",
    "                                    text='Mitochondrial Genome Network with Detected Communities',\n",
    "                                    font=dict(size=16)\n",
    "                                ),\n",
    "                                showlegend=True, # Ensure legend is shown\n",
    "                                hovermode='closest',\n",
    "                                margin=dict(b=20,l=5,r=5,t=40),\n",
    "                                annotations=[ dict(\n",
    "                                    text=\"Nodes colored by detected community. Click legend to toggle visibility. <br>Set 'highlight_cluster_id' to focus on a specific cluster.\",\n",
    "                                    showarrow=False,\n",
    "                                    xref=\"paper\", yref=\"paper\",\n",
    "                                    x=0.005, y=-0.002 ) ],\n",
    "                                xaxis=dict(showgrid=False, zeroline=False, showticklabels=False, mirror=True),\n",
    "                                yaxis=dict(showgrid=False, zeroline=False, showticklabels=False, mirror=True),\n",
    "                                height=800,\n",
    "                                template=\"plotly_white\"\n",
    "                            ))\n",
    "\n",
    "    pyo.iplot(fig_cluster)\n",
    "    html_output_path_cluster_plot = \"07_interactive_community_network_plot.html\"\n",
    "    fig_cluster.write_html(html_output_path_cluster_plot)\n",
    "    print(f\"Interactive community network plot saved as {html_output_path_cluster_plot}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 14: Network Statistics & Interpretation Report\n",
    "print(\"\\n--- Generating final network analysis report ---\")\n",
    "\n",
    "report_lines = []\n",
    "report_lines.append(\"=\"*70)\n",
    "report_lines.append(\"Mitochondrial Genome Network Analysis Report\")\n",
    "report_lines.append(\"=\"*70)\n",
    "report_lines.append(f\"Date: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "report_lines.append(f\"Input FASTA for analysis: {fasta_file}\")\n",
    "report_lines.append(f\"Similarity Threshold for Edges: {similarity_threshold}\")\n",
    "report_lines.append(\"\")\n",
    "\n",
    "if network.number_of_nodes() > 0:\n",
    "    report_lines.append(f\"Total Nodes (Mitochondrial Genomes): {network.number_of_nodes()}\")\n",
    "    report_lines.append(f\"Total Edges (Similarities > {similarity_threshold}): {network.number_of_edges()}\")\n",
    "    report_lines.append(f\"Network Density: {nx.density(network):.4f}\")\n",
    "    report_lines.append(f\"Number of Connected Components: {nx.number_connected_components(network)}\")\n",
    "    report_lines.append(\"\")\n",
    "\n",
    "    if network.number_of_edges() > 0:\n",
    "        report_lines.append(\"Top 10 Nodes by Degree Centrality:\")\n",
    "        degree_centrality = nx.degree_centrality(network)\n",
    "        sorted_degrees = sorted(degree_centrality.items(), key=lambda item: item[1], reverse=True)\n",
    "        for i, (node, degree_val) in enumerate(sorted_degrees[:10]):\n",
    "            organism = network.nodes[node].get('organism', 'N/A')\n",
    "            report_lines.append(f\"  {i+1}. {node} (Organism: {organism}, Degree Centrality: {degree_val:.4f})\")\n",
    "        report_lines.append(\"\")\n",
    "\n",
    "        report_lines.append(\"Nodes with Zero Degree (Isolated Nodes):\")\n",
    "        isolated_nodes = [node for node, degree in network.degree() if degree == 0]\n",
    "        if isolated_nodes:\n",
    "            for node in isolated_nodes:\n",
    "                organism = network.nodes[node].get('organism', 'N/A')\n",
    "                report_lines.append(f\"  - {node} (Organism: {organism})\")\n",
    "        else:\n",
    "            report_lines.append(\"  No isolated nodes found.\")\n",
    "        report_lines.append(\"\")\n",
    "\n",
    "        report_lines.append(\"Community Detection Summary:\")\n",
    "        if cluster_results:\n",
    "            for cluster_info in cluster_results:\n",
    "                report_lines.append(f\"  - Cluster {cluster_info['cluster_id']}:\")\n",
    "                report_lines.append(f\"    - Representative Organism: {cluster_info['representative_organism']}\")\n",
    "                report_lines.append(f\"    - Number of Nodes: {cluster_info['num_nodes_in_cluster']}\")\n",
    "        else:\n",
    "            report_lines.append(\"  Community detection was not performed or yielded no clusters.\")\n",
    "        report_lines.append(\"\")\n",
    "\n",
    "        report_lines.append(\"Output Files Generated:\")\n",
    "        report_lines.append(f\"  - Interactive Network Plot: {html_output_path}\")\n",
    "        report_lines.append(f\"  - Network Node Data (with centrality): {output_nodes_csv}\")\n",
    "        report_lines.append(f\"  - Network Edge Data: {output_edges_csv}\")\n",
    "        report_lines.append(f\"  - Network Node Data (with cluster IDs): {output_nodes_clustered_csv}\")\n",
    "        report_lines.append(f\"  - Cluster Summary: {output_clusters_csv}\")\n",
    "        report_lines.append(\"\")\n",
    "\n",
    "        report_lines.append(\"Suggestions for Further Analysis:\")\n",
    "        report_lines.append(\"  - Visualizing the 'network_nodes_clustered.csv' and 'network_edges.csv' in external tools like Gephi or Cytoscape for more advanced layouts and visual analysis.\")\n",
    "        report_lines.append(\"  - Analyzing the distribution of centrality measures within and across clusters.\")\n",
    "        report_lines.append(\"  - Investigating the biological implications of distinct connected components and clusters, correlating them with taxonomic groups or ecological niches.\")\n",
    "        report_lines.append(\"  - Testing different similarity metrics or thresholds to observe changes in network topology and clustering.\")\n",
    "        report_lines.append(\"  - Deeper examination of the organisms within each cluster to confirm the biological relevance of the representative species.\")\n",
    "\n",
    "    else:\n",
    "        report_lines.append(\"The network could not be built or is too sparse (e.g., all similarities below threshold).\")\n",
    "        report_lines.append(\"Consider lowering the `similarity_threshold` or checking your input data for sufficient variation.\")\n",
    "else:\n",
    "    report_lines.append(\"No sequences were processed to build the network.\")\n",
    "    report_lines.append(\"Please check the input FASTA file and the feature extraction process.\")\n",
    "\n",
    "\n",
    "final_report = \"\\n\".join(report_lines)\n",
    "print(final_report)\n",
    "\n",
    "with open('06_network_analysis_report.txt', 'w') as f:\n",
    "    f.write(final_report)\n",
    "print(\"\\n✓ Network analysis complete! Report saved to 06_network_analysis_report.txt\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load data\n",
    "nodes_df = pd.read_csv('network_nodes_clustered.csv')\n",
    "edges_df = pd.read_csv('network_edges.csv')\n",
    "\n",
    "# Create Network Graph\n",
    "G = nx.Graph()\n",
    "\n",
    "# Add nodes with attributes\n",
    "for _, row in nodes_df.iterrows():\n",
    "    G.add_node(row['node_id'], cluster=row['cluster_id'], organism=row['organism'])\n",
    "\n",
    "# Add edges with similarity weights\n",
    "for _, row in edges_df.iterrows():\n",
    "    G.add_edge(row['source'], row['target'], weight=row['weight'])\n",
    "\n",
    "# Position nodes with a force-directed layout\n",
    "pos = nx.spring_layout(G, k=0.15, iterations=20, seed=42)\n",
    "\n",
    "# Assign distinct colors for each cluster\n",
    "clusters = nodes_df['cluster_id'].unique()\n",
    "colors = plt.cm.tab20(range(len(clusters)))\n",
    "color_map = {cluster: colors[i] for i, cluster in enumerate(clusters)}\n",
    "\n",
    "# Determine representative species per cluster\n",
    "representatives = nodes_df.groupby('cluster_id').first().reset_index()\n",
    "legend_labels = {row['cluster_id']: f\"Cluster {row['cluster_id']}: {row['organism']}\" \n",
    "                 for _, row in representatives.iterrows()}\n",
    "\n",
    "# Plotting the Network\n",
    "plt.figure(figsize=(16, 12))\n",
    "\n",
    "for cluster in clusters:\n",
    "    node_list = [node for node in G.nodes if G.nodes[node]['cluster'] == cluster]\n",
    "    nx.draw_networkx_nodes(G, pos,\n",
    "                           nodelist=node_list,\n",
    "                           node_size=50,\n",
    "                           node_color=[color_map[cluster]],\n",
    "                           label=legend_labels[cluster])\n",
    "\n",
    "# Draw edges with transparency based on similarity weight\n",
    "weights = [G[u][v]['weight'] for u, v in G.edges()]\n",
    "nx.draw_networkx_edges(G, pos, alpha=0.2, width=[w * 0.5 for w in weights])\n",
    "\n",
    "# Plot formatting\n",
    "plt.axis('off')\n",
    "plt.title('Mitochondrial Genome Similarity Network with Representative Species')\n",
    "plt.legend(title='Clusters & Representative Species', bbox_to_anchor=(1.05, 1), loc='upper left', fontsize='small')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# OPTIONAL: Additional Plot Suggested – Degree Centrality Distribution\n",
    "degree_centrality = nx.degree_centrality(G)\n",
    "centrality_values = list(degree_centrality.values())\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(centrality_values, bins=30, color='skyblue', edgecolor='black')\n",
    "plt.title('Distribution of Degree Centrality in Mitochondrial Genome Network')\n",
    "plt.xlabel('Degree Centrality')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define cricket species by common known genera (Acheta, Gryllus, etc.)\n",
    "cricket_genera = ['Acheta', 'Gryllus', 'Tachycines', 'Gryllotalpa', 'Gryllodes', 'Teleogryllus']\n",
    "\n",
    "# Identify cricket nodes\n",
    "cricket_nodes = [row['node_id'] for _, row in nodes_df.iterrows() if any(genus in row['organism'] for genus in cricket_genera)]\n",
    "\n",
    "# Plot with cricket nodes highlighted\n",
    "plt.figure(figsize=(18, 12))\n",
    "\n",
    "# Draw all nodes first\n",
    "nx.draw_networkx_nodes(G, pos,\n",
    "                       nodelist=G.nodes(),\n",
    "                       node_size=30,\n",
    "                       node_color='gray',\n",
    "                       alpha=0.3)\n",
    "\n",
    "# Highlight cricket nodes\n",
    "nx.draw_networkx_nodes(G, pos,\n",
    "                       nodelist=cricket_nodes,\n",
    "                       node_size=80,\n",
    "                       node_color='red',\n",
    "                       label='Cricket Species')\n",
    "\n",
    "# Draw edges\n",
    "nx.draw_networkx_edges(G, pos, alpha=0.2, width=[G[u][v]['weight']*0.5 for u, v in G.edges()])\n",
    "\n",
    "# Legend with clusters\n",
    "for cluster in clusters:\n",
    "    node_list = [node for node in G.nodes if G.nodes[node]['cluster'] == cluster and node not in cricket_nodes]\n",
    "    nx.draw_networkx_nodes(G, pos,\n",
    "                           nodelist=node_list,\n",
    "                           node_size=30,\n",
    "                           node_color=[color_map[cluster]],\n",
    "                           alpha=0.5,\n",
    "                           label=f'Cluster {cluster}')\n",
    "\n",
    "# Formatting\n",
    "plt.axis('off')\n",
    "plt.title('Mitochondrial Genome Similarity Network with Cricket Species Highlighted')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine representative species for each cluster (first species encountered for simplicity)\n",
    "representatives = nodes_df.groupby('cluster_id').first().reset_index()\n",
    "\n",
    "# Plot with representative species names\n",
    "plt.figure(figsize=(18, 12))\n",
    "\n",
    "for cluster in clusters:\n",
    "    node_list = [node for node in G.nodes if G.nodes[node]['cluster'] == cluster]\n",
    "    nx.draw_networkx_nodes(G, pos,\n",
    "                           nodelist=node_list,\n",
    "                           node_size=50,\n",
    "                           node_color=[color_map[cluster]],\n",
    "                           label=f'Cluster {cluster}')\n",
    "\n",
    "# Draw edges\n",
    "nx.draw_networkx_edges(G, pos, alpha=0.3, width=[G[u][v]['weight']*0.5 for u, v in G.edges()])\n",
    "\n",
    "# Annotate representative species\n",
    "for _, row in representatives.iterrows():\n",
    "    node_id = row['node_id']\n",
    "    organism = row['organism']\n",
    "    if node_id in pos:\n",
    "        x, y = pos[node_id]\n",
    "        plt.text(x, y, organism, fontsize=9, fontweight='bold', ha='center', va='center',\n",
    "                 bbox=dict(facecolor='white', alpha=0.7, edgecolor='black', boxstyle='round,pad=0.2'))\n",
    "\n",
    "# Formatting\n",
    "plt.axis('off')\n",
    "plt.title('Mitochondrial Genome Similarity Network with Representative Species')\n",
    "plt.legend(title='Clusters', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List species within Cluster 0\n",
    "cluster_0_species = nodes_df[nodes_df['cluster_id'] == 0]['organism'].unique()\n",
    "\n",
    "cluster_0_species\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the species listed in Cluster 0 are indeed crickets (Family Gryllidae) or closely related species within Ensifera (long-horned Orthoptera). However, not all belong strictly to the family Gryllidae.\n",
    "\n",
    "Clarified Classification:\n",
    "Gryllidae (true crickets):\n",
    "\n",
    "Acheta domesticus (house cricket)\n",
    "\n",
    "Gryllus bimaculatus (two-spotted cricket)\n",
    "\n",
    "Gryllus lineaticeps\n",
    "\n",
    "Gryllus veletis\n",
    "\n",
    "Loxoblemmus doenitzi\n",
    "\n",
    "Tarbinskiellus portentosus\n",
    "\n",
    "Tarbinskiellus sp.\n",
    "\n",
    "Teleogryllus emma\n",
    "\n",
    "Teleogryllus infernalis\n",
    "\n",
    "Teleogryllus mitratus\n",
    "\n",
    "Teleogryllus occipitalis\n",
    "\n",
    "Teleogryllus oceanicus\n",
    "\n",
    "Turanogryllus eous\n",
    "\n",
    "Velarifictorus hemelytrus\n",
    "\n",
    "Xenogryllus lamottei\n",
    "\n",
    "Xenogryllus maniema\n",
    "\n",
    "Xenogryllus marmoratus\n",
    "\n",
    "Truljalia hibinonis\n",
    "\n",
    "Gryllacrididae (raspy crickets):\n",
    "\n",
    "Phryganogryllacris superangulata (not a true cricket, but closely related)\n",
    "\n",
    "Other related genera:\n",
    "\n",
    "Nisitrus vittatus (family Gryllidae or related subfamilies; considered cricket-like)\n",
    "\n",
    "Pseudolebinthus sp. (Gryllidae or closely related cricket genus)\n",
    "\n",
    "Sclerogryllus punctatus (Gryllidae or closely related cricket genus)\n",
    "\n",
    "Euscyrtinae sp. (generally classified within Gryllidae or cricket-related group)\n",
    "\n",
    "Summary:\n",
    "The cluster predominantly includes true cricket species (family Gryllidae), with a few related genera such as Phryganogryllacris from Gryllacrididae, indicating that this cluster broadly represents cricket-like Orthoptera, particularly within the Ensifera lineage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract species lists for specified clusters\n",
    "clusters_of_interest = [0, 3, 5, 7, 24]\n",
    "cluster_species_lists = {cluster: nodes_df[nodes_df['cluster_id'] == cluster]['organism'].unique().tolist()\n",
    "                         for cluster in clusters_of_interest}\n",
    "\n",
    "# Display clearly in a structured dictionary format\n",
    "cluster_species_lists\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cluster 0 (Primarily Gryllidae)\n",
    "Acheta domesticus, Euscyrtinae sp., Gryllus bimaculatus, Gryllus lineaticeps, Gryllus veletis, Loxoblemmus doenitzi, Nisitrus vittatus, Phryganogryllacris superangulata, Pseudolebinthus sp., Sclerogryllus punctatus, Tarbinskiellus portentosus, Tpa_asm: Tarbinskiellus, Tarbinskiellus sp., Teleogryllus emma, Teleogryllus infernalis, Teleogryllus mitratus, Teleogryllus occipitalis, Teleogryllus oceanicus, Truljalia hibinonis, Turanogryllus eous, Velarifictorus hemelytrus, Xenogryllus lamottei, Xenogryllus maniema, Xenogryllus marmoratus\n",
    "\n",
    "Cluster 3 (Mixed, primarily Ensifera)\n",
    "Anabropsis spp., Pteranabropsis spp., Cacoplistes rogenhoferi, Cardiodactylus muiri, Gryllotalpa spp., Dianemobius spp., Diestramima spp., Stenopelmatus spp., and many other related genera.\n",
    "\n",
    "Cluster 5 (Cave cricket, Rhaphidophoridae)\n",
    "Tachycines zorzini\n",
    "\n",
    "Cluster 7 (Mixed, Ensifera)\n",
    "Anabrus simplex, Alloxiphidiopsis emarginata, Gryllotalpa spp., Gryllodes spp., Phaneroptera spp., Xiphidiopsis spp., Xizicus spp., and numerous other diverse genera.\n",
    "\n",
    "Cluster 24 (Cave cricket, Rhaphidophoridae)\n",
    "Tachycines shuangcha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load data\n",
    "nodes_df = pd.read_csv('network_nodes_clustered.csv')\n",
    "edges_df = pd.read_csv('network_edges.csv')\n",
    "\n",
    "# Create overall graph\n",
    "G = nx.Graph()\n",
    "\n",
    "# Add nodes with cluster info\n",
    "for _, row in nodes_df.iterrows():\n",
    "    G.add_node(row['node_id'], cluster=row['cluster_id'], organism=row['organism'])\n",
    "\n",
    "# Add edges with similarity scores\n",
    "for _, row in edges_df.iterrows():\n",
    "    G.add_edge(row['source'], row['target'], weight=row['weight'])\n",
    "\n",
    "# Select clusters to plot separately\n",
    "selected_clusters = [0, 3, 5, 7, 24]\n",
    "\n",
    "# Plot separate network graphs for each cluster\n",
    "for cluster_id in selected_clusters:\n",
    "    # Extract nodes belonging to the current cluster\n",
    "    cluster_nodes = [node for node, data in G.nodes(data=True) if data['cluster'] == cluster_id]\n",
    "    \n",
    "    # Create subgraph for the current cluster\n",
    "    subG = G.subgraph(cluster_nodes)\n",
    "    \n",
    "    # Position nodes\n",
    "    pos = nx.spring_layout(subG, k=0.15, iterations=20, seed=42)\n",
    "    \n",
    "    # Plotting\n",
    "    plt.figure(figsize=(12, 9))\n",
    "    nx.draw_networkx_nodes(subG, pos, node_size=100, node_color='skyblue', alpha=0.9)\n",
    "    nx.draw_networkx_edges(subG, pos, alpha=0.5, width=[subG[u][v]['weight']*0.5 for u, v in subG.edges()])\n",
    "    nx.draw_networkx_labels(subG, pos, labels={node: data['organism'] for node, data in subG.nodes(data=True)}, \n",
    "                            font_size=8, font_color='darkblue')\n",
    "    \n",
    "    # Title and formatting\n",
    "    plt.title(f'Network Visualization of Cluster {cluster_id}', fontsize=16)\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load data\n",
    "nodes_df = pd.read_csv('network_nodes_clustered.csv')\n",
    "edges_df = pd.read_csv('network_edges.csv')\n",
    "\n",
    "# Create overall graph\n",
    "G = nx.Graph()\n",
    "\n",
    "# Add nodes with attributes\n",
    "for _, row in nodes_df.iterrows():\n",
    "    G.add_node(row['node_id'], cluster=row['cluster_id'], organism=row['organism'])\n",
    "\n",
    "# Add edges with similarity weights\n",
    "for _, row in edges_df.iterrows():\n",
    "    G.add_edge(row['source'], row['target'], weight=row['weight'])\n",
    "\n",
    "# Define cricket genera to highlight\n",
    "cricket_genera = ['Acheta', 'Gryllus', 'Tachycines', 'Gryllotalpa', 'Gryllodes', 'Teleogryllus', \n",
    "                  'Velarifictorus', 'Xenogryllus', 'Truljalia', 'Tarbinskiellus', 'Loxoblemmus']\n",
    "\n",
    "def is_cricket(organism):\n",
    "    return any(genus in organism for genus in cricket_genera)\n",
    "\n",
    "# Select clusters to visualize\n",
    "selected_clusters = [0, 3, 5, 7, 24]\n",
    "\n",
    "for cluster_id in selected_clusters:\n",
    "    # Nodes in the current cluster\n",
    "    cluster_nodes = [node for node, data in G.nodes(data=True) if data['cluster'] == cluster_id]\n",
    "    \n",
    "    # Subgraph\n",
    "    subG = G.subgraph(cluster_nodes)\n",
    "    \n",
    "    # Position nodes\n",
    "    pos = nx.spring_layout(subG, k=0.15, iterations=20, seed=42)\n",
    "    \n",
    "    # Identify cricket nodes\n",
    "    cricket_nodes = [node for node, data in subG.nodes(data=True) if is_cricket(data['organism'])]\n",
    "    non_cricket_nodes = [node for node in subG.nodes if node not in cricket_nodes]\n",
    "    \n",
    "    # Plotting\n",
    "    plt.figure(figsize=(14, 10))\n",
    "    \n",
    "    # Non-cricket nodes\n",
    "    nx.draw_networkx_nodes(subG, pos, nodelist=non_cricket_nodes, \n",
    "                           node_size=150, node_color='lightgray', alpha=0.8, label='Other Species')\n",
    "    \n",
    "    # Cricket nodes\n",
    "    nx.draw_networkx_nodes(subG, pos, nodelist=cricket_nodes, \n",
    "                           node_size=200, node_color='red', alpha=0.9, label='Cricket Species')\n",
    "    \n",
    "    # Edges\n",
    "    nx.draw_networkx_edges(subG, pos, alpha=0.4, width=[subG[u][v]['weight']*0.5 for u, v in subG.edges()])\n",
    "    \n",
    "    # Species labels\n",
    "    nx.draw_networkx_labels(subG, pos, labels={node: subG.nodes[node]['organism'] for node in subG.nodes()},\n",
    "                            font_size=8, font_color='black')\n",
    "    \n",
    "    # Formatting\n",
    "    plt.title(f'Network of Cluster {cluster_id} with Highlighted Cricket Species', fontsize=16)\n",
    "    plt.legend(scatterpoints=1, fontsize=12)\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
